#!/bin/bash

# Opttius Performance Optimization Toolkit
# Script conjunto para implementar todas las mejoras recomendadas

set -e  # Exit on any error

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
LOG_FILE="${PROJECT_ROOT}/optimization-log.txt"
DATABASE_URL="postgresql://postgres:postgres@127.0.0.1:54322/postgres"

echo "========================================"
echo "Opttius Performance Optimization Toolkit"
echo "========================================"
echo ""

# Function to log messages
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

# Function to check prerequisites
check_prerequisites() {
    log "Checking prerequisites..."
    
    # Check if Supabase is running
    if ! docker ps | grep -q "supabase"; then
        log "${RED}ERROR: Supabase containers are not running${NC}"
        log "Please start Supabase with: npm run supabase:start"
        exit 1
    fi
    
    # Check if psql is available
    if ! command -v psql &> /dev/null; then
        log "${YELLOW}WARNING: psql not found, using docker exec instead${NC}"
    fi
    
    # Check if node modules are installed
    if [ ! -d "node_modules" ]; then
        log "${RED}ERROR: Node modules not found${NC}"
        log "Please run: npm install"
        exit 1
    fi
    
    log "${GREEN}✓ All prerequisites met${NC}"
}

# Function to backup database
backup_database() {
    log "Creating database backup..."
    
    TIMESTAMP=$(date +%Y%m%d_%H%M%S)
    BACKUP_FILE="${PROJECT_ROOT}/backups/opttius_backup_${TIMESTAMP}.sql"
    
    mkdir -p "${PROJECT_ROOT}/backups"
    
    if command -v pg_dump &> /dev/null; then
        pg_dump "$DATABASE_URL" > "$BACKUP_FILE"
    else
        docker exec supabase_db_web pg_dump -U postgres postgres > "$BACKUP_FILE"
    fi
    
    if [ $? -eq 0 ]; then
        log "${GREEN}✓ Database backed up to: $BACKUP_FILE${NC}"
    else
        log "${RED}ERROR: Failed to create database backup${NC}"
        exit 1
    fi
}

# Function to run database performance analysis
analyze_performance() {
    log "Running database performance analysis..."
    
    # Enable pg_stat_statements if not already enabled
    docker exec supabase_db_web psql -U postgres -d postgres -c "
        CREATE EXTENSION IF NOT EXISTS pg_stat_statements;
        SELECT * FROM pg_extension WHERE extname = 'pg_stat_statements';
    " > /dev/null 2>&1
    
    # Analyze current performance
    PERFORMANCE_REPORT="${PROJECT_ROOT}/performance-analysis-$(date +%Y%m%d).md"
    
    cat > "$PERFORMANCE_REPORT" << EOF
# Database Performance Analysis Report
Generated: $(date)

## Current Slow Queries (Top 10)

EOF
    
    docker exec supabase_db_web psql -U postgres -d postgres -c "
        SELECT 
            query,
            calls,
            total_time,
            mean_time,
            stddev_time,
            rows
        FROM pg_stat_statements 
        WHERE mean_time > 50
        ORDER BY mean_time DESC 
        LIMIT 10;
    " >> "$PERFORMANCE_REPORT"
    
    log "${GREEN}✓ Performance analysis saved to: $PERFORMANCE_REPORT${NC}"
}

# Function to implement critical database indexes
implement_indexes() {
    log "Implementing critical database indexes..."
    
    INDEX_SCRIPT="${PROJECT_ROOT}/scripts/implement-critical-indexes.sql"
    
    cat > "$INDEX_SCRIPT" << 'EOF'
-- Critical Indexes Implementation
-- Generated by Opttius Optimization Toolkit

-- Foreign Key Performance Indexes
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_orders_customer_id ON public.orders(customer_id);
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_quotes_branch_id ON public.quotes(branch_id);
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_work_orders_assigned_to ON public.lab_work_orders(assigned_to);
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_appointments_professional_id ON public.appointments(professional_id);
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_products_category_id ON public.products(category_id);

-- Composite Indexes for Common Queries
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_appointments_branch_date_status 
ON public.appointments(branch_id, appointment_date, status);

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_orders_branch_created 
ON public.orders(branch_id, created_at DESC);

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_quotes_customer_created 
ON public.quotes(customer_id, created_at DESC);

-- Partial Indexes for Filtered Queries
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_products_active_featured 
ON public.products(is_active, is_featured, category_id) 
WHERE is_active = true;

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_customers_active_rut 
ON public.customers(is_active, rut) 
WHERE is_active = true;

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_work_orders_status_branch 
ON public.lab_work_orders(status, branch_id) 
WHERE status IN ('in_process', 'ready', 'quality_control');

-- Functional Indexes
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_profiles_rut_normalized 
ON public.profiles(normalize_rut_for_search(rut)) 
WHERE rut IS NOT NULL;
EOF
    
    # Execute the index creation
    docker exec -i supabase_db_web psql -U postgres -d postgres < "$INDEX_SCRIPT"
    
    if [ $? -eq 0 ]; then
        log "${GREEN}✓ Critical indexes implemented successfully${NC}"
    else
        log "${RED}ERROR: Failed to implement indexes${NC}"
        exit 1
    fi
}

# Function to optimize queries
optimize_queries() {
    log "Optimizing database queries..."
    
    OPTIMIZATION_SCRIPT="${PROJECT_ROOT}/scripts/query-optimizations.sql"
    
    cat > "$OPTIMIZATION_SCRIPT" << 'EOF'
-- Query Optimizations
-- Generated by Opttius Optimization Toolkit

-- Update statistics for query planner
ANALYZE public.products;
ANALYZE public.orders;
ANALYZE public.customers;
ANALYZE public.appointments;
ANALYZE public.quotes;
ANALYZE public.lab_work_orders;

-- Create optimized functions
CREATE OR REPLACE FUNCTION public.get_branch_appointments_optimized(
    p_branch_id UUID,
    p_date DATE
)
RETURNS TABLE (
    id UUID,
    customer_name TEXT,
    appointment_time TIME,
    service_type TEXT,
    status TEXT
)
LANGUAGE sql
STABLE
AS $$
    SELECT 
        a.id,
        COALESCE(c.first_name || ' ' || c.last_name, 'Cliente no registrado') as customer_name,
        a.appointment_time,
        a.service_type,
        a.status
    FROM public.appointments a
    LEFT JOIN public.customers c ON a.customer_id = c.id
    WHERE a.branch_id = p_branch_id 
    AND a.appointment_date = p_date
    AND a.status != 'cancelled'
    ORDER BY a.appointment_time
$$;

-- Create materialized view for dashboard statistics
CREATE MATERIALIZED VIEW IF NOT EXISTS public.dashboard_stats AS
SELECT 
    DATE_TRUNC('day', created_at) as date,
    COUNT(*) as total_orders,
    SUM(total_amount) as revenue,
    COUNT(DISTINCT customer_id) as unique_customers
FROM public.orders
WHERE created_at >= CURRENT_DATE - INTERVAL '30 days'
GROUP BY DATE_TRUNC('day', created_at)
ORDER BY date DESC;

-- Refresh the materialized view
REFRESH MATERIALIZED VIEW public.dashboard_stats;
EOF
    
    docker exec -i supabase_db_web psql -U postgres -d postgres < "$OPTIMIZATION_SCRIPT"
    
    log "${GREEN}✓ Query optimizations applied${NC}"
}

# Function to setup monitoring
setup_monitoring() {
    log "Setting up monitoring infrastructure..."
    
    MONITORING_SCRIPT="${PROJECT_ROOT}/scripts/setup-monitoring.sql"
    
    cat > "$MONITORING_SCRIPT" << 'EOF'
-- Monitoring Setup
-- Generated by Opttius Optimization Toolkit

-- Create monitoring views
CREATE OR REPLACE VIEW public.database_health AS
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
    (xpath('/row/c/text()', query_to_xml(format('select count(*) as c from %I.%I', schemaname, tablename), false, true, '')))[1]::text::int as row_count,
    last_autoanalyze,
    last_autovacuum
FROM pg_tables 
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- Create performance monitoring function
CREATE OR REPLACE FUNCTION public.check_performance_issues()
RETURNS TABLE (
    issue_type TEXT,
    description TEXT,
    severity TEXT
)
LANGUAGE plpgsql
AS $$
BEGIN
    -- Check for missing indexes on foreign keys
    RETURN QUERY
    SELECT 
        'missing_index'::TEXT as issue_type,
        format('Missing index on foreign key: %I.%I', tc.table_name, kcu.column_name)::TEXT as description,
        'medium'::TEXT as severity
    FROM information_schema.table_constraints AS tc
    JOIN information_schema.key_column_usage AS kcu
        ON tc.constraint_name = kcu.constraint_name
        AND tc.table_schema = kcu.table_schema
    WHERE tc.constraint_type = 'FOREIGN KEY'
    AND tc.table_schema = 'public'
    AND NOT EXISTS (
        SELECT 1 FROM pg_indexes i
        WHERE i.tablename = tc.table_name
        AND i.indexdef ILIKE '%' || kcu.column_name || '%'
    );
    
    -- Check for tables without primary keys
    RETURN QUERY
    SELECT 
        'no_primary_key'::TEXT as issue_type,
        format('Table %I has no primary key', t.table_name)::TEXT as description,
        'high'::TEXT as severity
    FROM information_schema.tables t
    WHERE t.table_schema = 'public'
    AND t.table_type = 'BASE TABLE'
    AND NOT EXISTS (
        SELECT 1 FROM information_schema.table_constraints tc
        WHERE tc.table_name = t.table_name
        AND tc.table_schema = t.table_schema
        AND tc.constraint_type = 'PRIMARY KEY'
    );
END;
$$;

-- Schedule regular maintenance
SELECT cron.schedule(
    'database-maintenance',
    '0 2 * * *',  -- Daily at 2 AM
    $$REFRESH MATERIALIZED VIEW public.dashboard_stats$$
);
EOF
    
    docker exec -i supabase_db_web psql -U postgres -d postgres < "$MONITORING_SCRIPT"
    
    log "${GREEN}✓ Monitoring infrastructure setup complete${NC}"
}

# Function to run integration tests
run_integration_tests() {
    log "Running integration tests..."
    
    npm run test:integration
    
    if [ $? -eq 0 ]; then
        log "${GREEN}✓ All integration tests passed${NC}"
    else
        log "${RED}ERROR: Integration tests failed${NC}"
        exit 1
    fi
}

# Function to generate optimization report
generate_report() {
    log "Generating optimization report..."
    
    REPORT_FILE="${PROJECT_ROOT}/optimization-report-$(date +%Y%m%d).md"
    
    cat > "$REPORT_FILE" << EOF
# Opttius Optimization Report
Generated: $(date)

## Summary

This report summarizes the performance optimizations applied to the Opttius system.

## Changes Implemented

### Database Indexes
- Added 12 critical indexes for improved query performance
- Created composite indexes for common query patterns
- Implemented partial indexes for filtered queries

### Query Optimizations
- Updated database statistics for better query planning
- Created optimized functions for frequent operations
- Implemented materialized views for dashboard data

### Monitoring
- Setup database health monitoring views
- Created performance issue detection functions
- Established regular maintenance schedules

## Performance Improvements

Expected improvements:
- 40-60% reduction in query execution time
- Better handling of concurrent users
- Improved dashboard loading times
- Enhanced data consistency

## Next Steps

1. Monitor performance metrics for 1 week
2. Review slow query logs
3. Fine-tune indexes based on actual usage patterns
4. Implement additional optimizations as needed

---
Report generated by Opttius Optimization Toolkit
EOF
    
    log "${GREEN}✓ Optimization report saved to: $REPORT_FILE${NC}"
}

# Main execution flow
main() {
    case "${1:-full}" in
        "prerequisites")
            check_prerequisites
            ;;
        "backup")
            backup_database
            ;;
        "analyze")
            analyze_performance
            ;;
        "indexes")
            implement_indexes
            ;;
        "optimize")
            optimize_queries
            ;;
        "monitoring")
            setup_monitoring
            ;;
        "test")
            run_integration_tests
            ;;
        "report")
            generate_report
            ;;
        "full"|*)
            log "Starting full optimization process..."
            
            check_prerequisites
            backup_database
            analyze_performance
            implement_indexes
            optimize_queries
            setup_monitoring
            run_integration_tests
            generate_report
            
            log "${GREEN}"
            log "========================================"
            log "Optimization process completed successfully!"
            log "========================================"
            log ""
            log "Key achievements:"
            log "- Database backup created"
            log "- Performance baseline established"
            log "- Critical indexes implemented"
            log "- Query optimizations applied"
            log "- Monitoring infrastructure setup"
            log "- Integration tests passed"
            log ""
            log "Next steps:"
            log "1. Review the optimization report"
            log "2. Monitor system performance for 24-48 hours"
            log "3. Check the performance dashboard"
            log "4. Validate all functionality works correctly"
            log "${NC}"
            ;;
    esac
}

# Run main function
main "$@"